#' Optimize a model for SFS simulation by downsampling to uniform sample sizes
#' @description Analyzes the per-locus, per-population sample sizes in a model object
#'   and finds the optimal downsampling scheme that removes individuals and loci while
#'   maximizing the total amount of retained data. This ensures all loci have uniform
#'   sample sizes, which is required for SFS-based inference with tools like
#'   fastsimcoal2, dadi, and moments.
#'
#'   The optimization maximizes the score: n_retained_loci * total_samples_per_locus.
#'   A locus is retained only if all its per-population sample sizes meet or exceed
#'   the target thresholds. Retained loci are then downsampled to the target sizes.
#'
#' @param model A model object built by the main.menu function.
#' @param target Optional numeric vector of per-population target sample sizes.
#'   Length must equal the number of populations. If NULL (default), the optimal
#'   targets are found automatically.
#' @return A modified model object with uniform sample sizes across all loci,
#'   ready for use with \code{sim.sfs}.
#' @examples
#' \dontrun{
#' data("A_piscivorus", package = "PipeMaster")
#'
#' # Automatic optimization
#' Is_sfs <- optimize.sfs.model(Is)
#'
#' # Manual target: keep loci with at least 40 in pop1 and 14 in pop2
#' Is_manual <- optimize.sfs.model(Is, target = c(40, 14))
#'
#' # Then simulate SFS
#' sim.sfs(model = Is_sfs, nsim.blocks = 1, block.size = 100,
#'              path = tempdir(), output.name = "test")
#' }
#' @author Marcelo Gehara
#' @export
optimize.sfs.model <- function(model, target = NULL) {

  if(class(model) != "Model") {
    stop("Argument should be an object of class Model generated by the main.menu() function.")
  }

  npop <- as.numeric(model$I[1, 3])
  nloci <- nrow(model$loci)
  pop_cols <- 4:(3 + npop)

  # Extract per-population sample sizes as numeric matrix
  pop_sizes <- matrix(as.numeric(model$I[, pop_cols]), ncol = npop)

  # Check if already uniform
  if(nrow(unique(pop_sizes)) == 1) {
    cat("Model already has uniform sample sizes across all loci. No changes needed.\n")
    return(model)
  }

  cat("=== SFS Model Optimization ===\n\n")
  cat("Populations:", npop, "\n")
  cat("Original loci:", nloci, "\n\n")

  cat("Per-population sample sizes (original):\n")
  for(p in 1:npop) {
    rng <- range(pop_sizes[, p])
    cat(sprintf("  Pop %d: min=%d, max=%d, median=%.0f, unique values=%d\n",
                p, rng[1], rng[2], median(pop_sizes[, p]),
                length(unique(pop_sizes[, p]))))
  }
  cat("\n")

  if(is.null(target)) {
    # Automatic optimization via grid search
    unique_per_pop <- lapply(1:npop, function(p) sort(unique(pop_sizes[, p])))

    # Limit grid size for efficiency
    total_combos <- prod(sapply(unique_per_pop, length))
    if(total_combos > 500000) {
      n_per_pop <- floor(500000^(1 / npop))
      unique_per_pop <- lapply(unique_per_pop, function(vals) {
        if(length(vals) <= n_per_pop) return(vals)
        as.numeric(unique(quantile(vals, probs = seq(0, 1, length.out = n_per_pop), type = 1)))
      })
      cat("Note: Search space reduced for efficiency.\n\n")
    }

    grid <- expand.grid(unique_per_pop)

    # Compute score for each threshold combination
    scores <- apply(grid, 1, function(tgt) {
      tgt <- as.numeric(tgt)
      kept <- rowSums(pop_sizes >= matrix(tgt, nrow = nloci, ncol = npop, byrow = TRUE)) == npop
      sum(kept) * sum(tgt)
    })

    best_idx <- which.max(scores)
    target <- as.numeric(grid[best_idx, ])

    # Show top alternatives
    top_idx <- order(scores, decreasing = TRUE)[1:min(5, length(scores))]
    cat("Top optimization results (score = loci x total_samples):\n")
    header <- sprintf("  %-5s", "Rank")
    for(p in 1:npop) header <- paste0(header, sprintf("  Pop%-2d", p))
    header <- paste0(header, "  Loci    Score")
    cat(header, "\n")

    for(rank in seq_along(top_idx)) {
      idx <- top_idx[rank]
      tgt <- as.numeric(grid[idx, ])
      kept <- sum(rowSums(pop_sizes >= matrix(tgt, nrow = nloci, ncol = npop, byrow = TRUE)) == npop)
      line <- sprintf("  %-5d", rank)
      for(p in 1:npop) line <- paste0(line, sprintf("  %-6d", tgt[p]))
      line <- paste0(line, sprintf("  %-6d  %d", kept, scores[idx]))
      if(rank == 1) line <- paste0(line, "  <-- selected")
      cat(line, "\n")
    }
    cat("\n")

  } else {
    # Manual target
    if(length(target) != npop) {
      stop("target must be a vector of length ", npop, " (one value per population).")
    }
    cat("Using manually specified target sample sizes.\n\n")
  }

  # Determine which loci to keep
  keep <- rowSums(pop_sizes >= matrix(target, nrow = nloci, ncol = npop, byrow = TRUE)) == npop
  n_kept <- sum(keep)

  if(n_kept == 0) {
    stop("No loci meet the specified thresholds. Try lower target values.")
  }

  cat("Target sample sizes:\n")
  for(p in 1:npop) {
    cat(sprintf("  Pop %d: %d\n", p, target[p]))
  }
  cat(sprintf("  Total per locus: %d\n\n", sum(target)))
  cat(sprintf("Retained loci: %d of %d (%.1f%%)\n", n_kept, nloci, 100 * n_kept / nloci))
  cat(sprintf("Removed loci: %d\n\n", nloci - n_kept))

  # Apply to model: filter loci and set uniform sizes
  model$I <- model$I[keep, , drop = FALSE]
  model$loci <- model$loci[keep, , drop = FALSE]

  for(p in 1:npop) {
    model$I[, 3 + p] <- as.character(target[p])
  }

  cat("Model updated successfully.\n")
  return(model)
}
